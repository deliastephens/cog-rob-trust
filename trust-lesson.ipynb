{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trust in Multi-Agent Systems\n",
    "Welcome to our lesson on trust and explainability in AI! \n",
    "\n",
    "Before we get started, remember to run this cell to get everything set up correctly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from utils import prep_browser, run_pyperplan, run_and_viz_pyperplan\n",
    "\n",
    "from pyperplan import task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "\nrequire(\"notebook/js/outputarea\").OutputArea.prototype._should_scroll = function(lines) {\n    return false;\n}\n\nvar tinycolor;\n\nrequire.config({\n  paths: {\n      sha1: 'http://editor.planning.domains/plugins/featured/timeline-viewer/sha1.js',\n      charts: 'https://www.gstatic.com/charts/loader.js'\n  }\n});\n\nrequirejs(['https://www.gstatic.com/charts/loader.js'],\n          function() {\n              google.charts.load('current', {packages: ['timeline']});\n         });\n\nrequirejs(['https://courses.csail.mit.edu/16.410/js/sha1.js'],\n          function() {\n              console.log('Loaded SHA1');\n         });\n\nrequirejs(['https://courses.csail.mit.edu/16.410/js/tinycolor.js'],\n          function(m) {\n              console.log('Loaded tinycolor');\n              tinycolor = m;\n         });\n\nfunction get_terms(pred) {\n  // Cut off the first and last characters - the parenthesis\n  pred = pred.trim().slice(1, pred.length - 1);\n  var words = pred.split(\" \");\n  return words;\n}\n\nfunction wordToColor(word, sat, lightness) {\n  // Helper function that converts a word to a color based on the SHA1 sum\n  var sha1_word = CryptoJS.SHA1(word).words[0];\n  sha1_word = sha1_word % 360;\n  if (sha1_word < 0) {\n    sha1_word += 360;\n  }\n  var hsl_string = 'hsl(' + sha1_word + \", \" + (100 * sat) + \"%, \" + (100 * lightness) + \"%)\";\n  return '#' + tinycolor(hsl_string).toHex();\n}\n\nfunction activity_to_table_row(match, id) {\n  var start_time = 1000*parseFloat(match[1]);\n  var end_time = 1000*parseFloat(match[3]) + start_time;\n  return [\"\" + id, match[2],  start_time, end_time];\n}\n\nfunction activity_to_color(match) {\n  var words = get_terms(match[2]);\n  var action_name = words[0].trim();\n  var color = wordToColor(action_name, 0.7, 0.75);\n  return color;\n}\n\nfunction display_timeline(chart_div, plan_string) {\n    requirejs(['https://www.gstatic.com/charts/loader.js'],\n        function() {\n            google.charts.load('current', {packages: ['timeline']});\n            google.charts.setOnLoadCallback(function () {display_timeline_cb(chart_div, plan_string)});\n        });\n}\n\nwindow.display_timeline = display_timeline;\n\nfunction display_timeline_cb(div_name, plan_string){\n    // Add the google chart\n    var options = {\n      height: 100,\n      animation: {\n        duration: 1000,\n        easing: 'out',\n      },\n      hAxis: {\n        gridlines: {count: 15}\n      },\n      timeline: {\n        showRowLabels: true,\n        groupByRowLabel: false,\n        colorByRowLabel: false,\n      }\n    };\n    var chart = new google.visualization.Timeline(document.getElementById(div_name));\n    \n    // Get planner text\n    var planner_output = plan_string;\n    // Find all matches for lines that appear to be temporal actions\n    var regexp = /^([\\d.]+)\\s*:\\s*(\\(.*\\))\\s*\\[([\\d.]+)\\]$/gm;\n    var matches = [];\n    var match;\n    while ((match = regexp.exec(planner_output)) !== null) {\n      matches.push(match);\n    }\n\n    // Load the data into a table\n    var data = new google.visualization.DataTable();\n    data.addColumn('string', 'Task ID');\n    data.addColumn('string', 'Task Name');\n    data.addColumn('number', 'Start');\n    data.addColumn('number', 'End');\n    data.addRows([]);\n    var colors_for_activities = [];\n    for(var i = 0; i < matches.length; i++) {\n        var match = matches[i];\n        data.addRows([activity_to_table_row(match, i)])\n        var color = activity_to_color(match)\n        colors_for_activities.push(color);\n    }\n\n    // Draw the chart!\n    options.height = data.getNumberOfRows() * 43 + 100;\n    options.colors = colors_for_activities;\n    chart.draw(data, options);\n}\n",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prep_browser()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explainability\n",
    "As discussed in lecture, we know that _explaining_ unexpected behaviors from our robot can increase trust. In this module, we'll see how this comes into play. Recall our human-aware planning problem from lecture:\n",
    "\n",
    "## Human-Aware Planning\n",
    "Recall the Human-Aware Planning problem described in [1](https://arxiv.org/pdf/2105.01220.pdf).\n",
    "\n",
    "**Input:**\n",
    "\n",
    "$\\mathcal{M}^R$, the robot's model of the environment and problem. Consists of the tuple $\\langle\\mathcal{D}^R, \\mathcal{I}^R, \\mathcal{G}^R\\rangle$, where $\\mathcal{D}^R$ is the domain,  $\\mathcal{I}^R$ is the initial state, and $\\mathcal{G}^R$ is the goal state.\n",
    "\n",
    "$\\mathcal{M}^G$, the human's model of the environment and problem. Consists of the tuple $\\langle\\mathcal{D}^H, \\mathcal{I}^H, \\mathcal{G}^H\\rangle$, where $\\mathcal{D}^H$ is the domain,  $\\mathcal{I}^H$ is the initial state, and $\\mathcal{G}^H$ is the goal state.\n",
    "\n",
    "**Output:**\n",
    "\n",
    "A _plan_; that is, a sequence of robot actions that achieve the goal state but also meets the human's expectations. We call the degree to which the robot plan $\\pi$ matches the human expectations $\\pi^e$ the plan _explicability_, and we often model it as the _distance_ $\\delta$ between $\\pi^e$ and $\\pi$:\n",
    "\n",
    "$$\n",
    "E(\\pi) = -1 * \\delta(\\pi^e, \\pi)\n",
    "$$\n",
    "\n",
    "A plan $\\pi$ is _perfectly explicable_ if $E(\\pi) = 0$. We often use the difference in costs between the two plans as our distance function, $\\delta$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1: Modeling Incomplete Knowledge\n",
    "Because we're so familiar with PDDL, we will model both of these problems in PDDL! Check out the references from `ps-03` if you've forgotten how to use it. **TODO: describe this stuff in more detail.**\n",
    "\n",
    "We'll start with a simplified version of the [Wumpus World](http://users.cecs.anu.edu.au/~patrik/pddlman/wumpus.html). Here, our robot is trying to navigate in a 3x3 grid to pick up a block. The robot knows that its shortest path is unencumbered, but the human has no idea--they think that there's piles of trash on the shortest path to the robot.\n",
    "\n",
    "![Wumpus World](res/wumpus-world.png)\n",
    "\n",
    "We've provided you with a fully modeled version of the robot world in `pddl/robot-domain.pddl` and `pddl/robot-problem.pddl`. Your task is to modify `pddl/human-domain.pddl` and `pddl/human-problem.pddl` so it reflects the fact that the _human_ thinks that there is trash in squares `(0, 2)` and `(1, 2)`. Notice that none of our actions are `durative-actions`; we assume a unit cost for every action.\n",
    "\n",
    "Instead of using Optic to run our plans, we'll use a Python PDDL Planner called [`pyperplan`](https://github.com/aibasel/pyperplan). Pyperplan is cool because it is extensible and contains a very clean implementation of some of the commmon search algorithms; if you're interested in the way planners work, definitely check out their codebase! Like Optic, however, Pyperplan only supports _positive preconditions._  \n",
    "\n",
    "Note, too, that we cannot specify negative initial conditions. This is important with our `clear` predicate. If we want to say that a square is not `clear` at the start, we simply omit it from the list of clear squares. See `robot-problem.pddl` for a concrete example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Op (robot-move robot1 sq2-2 sq2-1)>,\n",
       " <Op (robot-move robot1 sq2-1 sq1-1)>,\n",
       " <Op (robot-move robot1 sq1-1 sq0-1)>,\n",
       " <Op (robot-move robot1 sq0-1 sq0-2)>]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "domain_file = 'pddl/robot-domain.pddl'\n",
    "problem_file = 'pddl/robot-problem.pddl'\n",
    "\n",
    "run_pyperplan(domain_file, problem_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"alert alert-success\">\n",
       "      <strong>Plan found!</strong>\n",
       "      </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div id=\"timeline-graph-3\"></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<script> window.display_timeline(\"timeline-graph-3\", \"0.0: (robot-move robot1 sq2-2 sq2-1) [1.0]\\n1.0: (robot-move robot1 sq2-1 sq1-1) [1.0]\\n2.0: (robot-move robot1 sq1-1 sq0-1) [1.0]\\n3.0: (robot-move robot1 sq0-1 sq0-2) [1.0]\\n\") </script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<strong>raw planner output:</strong>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(robot-move robot1 sq2-2 sq2-1)\n",
      "  PRE: (at robot1 sq2-2)\n",
      "  ADD: (at robot1 sq2-1)\n",
      "  DEL: (at robot1 sq2-2)\n",
      "\n",
      "(robot-move robot1 sq2-1 sq1-1)\n",
      "  PRE: (at robot1 sq2-1)\n",
      "  ADD: (at robot1 sq1-1)\n",
      "  DEL: (at robot1 sq2-1)\n",
      "\n",
      "(robot-move robot1 sq1-1 sq0-1)\n",
      "  PRE: (at robot1 sq1-1)\n",
      "  ADD: (at robot1 sq0-1)\n",
      "  DEL: (at robot1 sq1-1)\n",
      "\n",
      "(robot-move robot1 sq0-1 sq0-2)\n",
      "  PRE: (at robot1 sq0-1)\n",
      "  ADD: (at robot1 sq0-2)\n",
      "  DEL: (at robot1 sq0-1)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_and_viz_pyperplan(domain_file, problem_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How might we modify this domain to represent the human's belief that there is trash at position $(1, 2)$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"alert alert-success\">\n",
       "      <strong>Plan found!</strong>\n",
       "      </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div id=\"timeline-graph-4\"></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<script> window.display_timeline(\"timeline-graph-4\", \"0.0: (robot-move robot1 sq2-2 sq2-1) [1.0]\\n1.0: (robot-move robot1 sq2-1 sq2-0) [1.0]\\n2.0: (robot-move robot1 sq2-0 sq1-0) [1.0]\\n3.0: (robot-move robot1 sq1-0 sq0-0) [1.0]\\n4.0: (robot-move robot1 sq0-0 sq0-1) [1.0]\\n5.0: (robot-move robot1 sq0-1 sq0-2) [1.0]\\n\") </script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<strong>raw planner output:</strong>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(robot-move robot1 sq2-2 sq2-1)\n",
      "  PRE: (at robot1 sq2-2)\n",
      "  ADD: (at robot1 sq2-1)\n",
      "  DEL: (at robot1 sq2-2)\n",
      "\n",
      "(robot-move robot1 sq2-1 sq2-0)\n",
      "  PRE: (at robot1 sq2-1)\n",
      "  ADD: (at robot1 sq2-0)\n",
      "  DEL: (at robot1 sq2-1)\n",
      "\n",
      "(robot-move robot1 sq2-0 sq1-0)\n",
      "  PRE: (at robot1 sq2-0)\n",
      "  ADD: (at robot1 sq1-0)\n",
      "  DEL: (at robot1 sq2-0)\n",
      "\n",
      "(robot-move robot1 sq1-0 sq0-0)\n",
      "  PRE: (at robot1 sq1-0)\n",
      "  ADD: (at robot1 sq0-0)\n",
      "  DEL: (at robot1 sq1-0)\n",
      "\n",
      "(robot-move robot1 sq0-0 sq0-1)\n",
      "  PRE: (at robot1 sq0-0)\n",
      "  ADD: (at robot1 sq0-1)\n",
      "  DEL: (at robot1 sq0-0)\n",
      "\n",
      "(robot-move robot1 sq0-1 sq0-2)\n",
      "  PRE: (at robot1 sq0-1)\n",
      "  ADD: (at robot1 sq0-2)\n",
      "  DEL: (at robot1 sq0-1)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "domain_file = 'pddl/human-domain.pddl'\n",
    "problem_file = 'pddl/human-problem.pddl'\n",
    "\n",
    "run_and_viz_pyperplan(domain_file, problem_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2: Plan Explainer\n",
    "\n",
    "If you were the human in this human-robot team, you'd probably be concerned if your robot started moving towards where you thought was a gigantic pile of trash! This corresponds to a _decrease in trust_. As discussed in lecture, there are several ways to deal with these trust decreases:\n",
    "\n",
    "**TODO: enumerate the ways trust can decrease**\n",
    "\n",
    "Today, we'll be focusing on _explaining_; that is, telling our robot it's probably a good idea to explain its actions when it takes unexpected actions. We'll accomplish this by modifying the PDDL plan with an `explain` action that has some cost."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try writing a function that will perform the robot's optimal plan, but explain to the human why their plans differ. We've implemented a few helper functions below to get you started, as well as outlined some pseudocode in the form of comments in the function `make_explainable_plan.` \n",
    "\n",
    "At a high-level, your function should take in as input an optimal robot plan and the expected human plan. It should then compare, action-by-action, the optimal action and the expected action, terminating when the optimal plan has reached the goal state. \n",
    "\n",
    "If the actions don't match up, you should check to see if the next optimal action is ever represented in the explainable plan. Then, you should skip to that action in the explainable plan and explain. \n",
    "\n",
    "**Todo: my implementation is certainly not robust enough and will need help debugging (i.e., what is the desired behavior if the human and robot plans converge? I think my code breaks in this case...)**\n",
    "\n",
    "**Todo: Describe the desired output, as well as the helper functions, in greater detail**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_action_agent(operator):\n",
    "    \"\"\"\n",
    "    Returns a string representing the agent completing some action\n",
    "    Example: get_operation_agent(<Op (robot-move robot1 sq2-0 sq1-0)>)\n",
    "            should return \"robot-1\".\n",
    "\n",
    "    @param operator:    A pyperplan Operator object\n",
    "\n",
    "    @return:            A string of the agent completing the operation \n",
    "    \"\"\"\n",
    "    return re.search(\"(?<=\\s)(.*?)(?=\\s)\", operator.name).group()\n",
    "\n",
    "def explain(agent):\n",
    "    \"\"\"\n",
    "    Returns an Operator (explain `AGENT`)\n",
    "    \"\"\"\n",
    "    return task.Operator('(explain ' + str(agent) + ')', frozenset(), frozenset(), frozenset())\n",
    "\n",
    "def calculate_plan_cost(plan):\n",
    "    \"\"\"Calculates the cost of a plan. In our case (because each action has a unit cost), \n",
    "    the plan cost is simply the length of the plan. \"\"\"\n",
    "    return len(plan)\n",
    "\n",
    "def compare_plans(optimal_plan, expected_plan):\n",
    "    # Initialize explained plan to the empty list\n",
    "    explained_plan = []\n",
    "\n",
    "    # Iterate through index in optimal plan\n",
    "    for i in range(len(optimal_plan)):\n",
    "        # Get optimal and expected action at step i\n",
    "        optimal_action = optimal_plan[i]\n",
    "        expected_action = expected_plan[i]\n",
    "\n",
    "        # Get the agent performing the optimal action\n",
    "        agent = get_action_agent(optimal_action)\n",
    "\n",
    "        # If the optimal action is what you'd expect, \n",
    "        # append the optimal action to the explained plan\n",
    "        if optimal_action == expected_action:\n",
    "            explained_plan.append(optimal_action)\n",
    "        # Otherwise, try to find the index \"next matching\" plan action \n",
    "        else:\n",
    "            try: \n",
    "                # See if the optimal action's add effects appear in the expected plan\n",
    "                # If they do, remove all of the actions in the expected plan\n",
    "                matching_index = [x.add_effects for x in expected_plan].index(optimal_action.add_effects)\n",
    "                expected_plan = expected_plan[:i] + expected_plan[matching_index:]\n",
    "                explained_plan.append(optimal_action)\n",
    "            except:\n",
    "                explained_plan.append(optimal_action)\n",
    "                explained_plan.append(explain(agent))\n",
    "\n",
    "    # Return the explained plan\n",
    "    return explained_plan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Op (robot-move robot1 sq2-2 sq2-1)>,\n",
       " <Op (robot-move robot1 sq2-1 sq1-1)>,\n",
       " <Op (explain robot1)>,\n",
       " <Op (robot-move robot1 sq1-1 sq0-1)>,\n",
       " <Op (robot-move robot1 sq0-1 sq0-2)>]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "human_domain_file = 'pddl/human-domain.pddl'\n",
    "human_problem_file = 'pddl/human-problem.pddl'\n",
    "\n",
    "robot_domain_file = 'pddl/robot-domain.pddl'\n",
    "robot_problem_file = 'pddl/robot-problem.pddl'\n",
    "\n",
    "expected_plan = run_pyperplan(human_domain_file, human_problem_file)\n",
    "optimal_plan = run_pyperplan(robot_domain_file, robot_problem_file)\n",
    "compare_plans(optimal_plan, expected_plan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Meta-MDP\n",
    "\n",
    "As discussed in class, one way of selecting robot behaviors can be modeled as a \"Meta-MDP\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2efb303a8c67ecba5167d2efb1d6294a5dab7ce44c08b1fa1f624f44f77a78fb"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
